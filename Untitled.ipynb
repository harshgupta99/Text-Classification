{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'misc.forsale'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolders=['alt.atheism' , 'comp.graphics' , 'comp.os.ms-windows.misc' , 'comp.sys.ibm.pc.hardware' , 'comp.sys.mac.hardware' , 'comp.windows.x' , 'misc.forsale' , 'rec.autos' , 'rec.motorcycles' , 'rec.sport.baseball' , 'rec.sport.hockey' , 'sci.crypt' , 'sci.electronics' , 'sci.med' , 'sci.space' , 'soc.religion.christian' , 'talk.politics.guns' , 'talk.politics.mideast' , 'talk.politics.misc' , 'talk.religion.misc']\n",
    "subfolders[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "DATA_DIRECTORY='20_newsgroups'\n",
    "\n",
    "def get_data(DATA_DIRECTORY):\n",
    "    data={}\n",
    "    for subfolder in subfolders:\n",
    "        data[subfolder]=[]\n",
    "    for subfolder in subfolders:\n",
    "        files=os.listdir(os.path.join(DATA_DIRECTORY,subfolder))\n",
    "        for file in files:\n",
    "            with open(os.path.join(DATA_DIRECTORY,subfolder,file),encoding=\"latin-1\") as f:\n",
    "                data[subfolder].append(f.read())\n",
    "    return data            \n",
    "# data is a dictionary \n",
    "# data['alt.atheism'] returns a list containing all the text inside alt.atheism category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cantaloupe',\n",
       " 'message',\n",
       " 'subject',\n",
       " 'lines',\n",
       " 'newsgroups',\n",
       " 'organization',\n",
       " 'state',\n",
       " 'writes',\n",
       " 'about',\n",
       " 'article',\n",
       " 'references',\n",
       " 'sender',\n",
       " 'howland',\n",
       " 'reston',\n",
       " 'people',\n",
       " 'university',\n",
       " 'posting',\n",
       " 'other',\n",
       " 'think',\n",
       " 'usenet',\n",
       " 'zaphod',\n",
       " 'politics',\n",
       " 'windows',\n",
       " 'rutgers',\n",
       " 'harvard',\n",
       " 'these',\n",
       " 'system',\n",
       " 'crabapple',\n",
       " 'because',\n",
       " 'europa',\n",
       " 'gtefsd',\n",
       " 'uunet',\n",
       " 'world',\n",
       " 'religion',\n",
       " 'those',\n",
       " 'christian',\n",
       " 'first',\n",
       " 'right',\n",
       " 'rochester',\n",
       " 'distribution',\n",
       " 'where',\n",
       " 'space',\n",
       " 'after',\n",
       " 'andrew',\n",
       " 'gatech',\n",
       " 'anyone',\n",
       " 'magnesium',\n",
       " 'reply',\n",
       " 'being',\n",
       " 'utexas',\n",
       " 'culture',\n",
       " 'really',\n",
       " 'please',\n",
       " 'something',\n",
       " 'problem',\n",
       " 'computer',\n",
       " 'believe',\n",
       " 'since',\n",
       " 'graphics',\n",
       " 'hardware',\n",
       " 'still',\n",
       " 'netcom',\n",
       " 'years',\n",
       " 'going',\n",
       " 'government',\n",
       " 'information',\n",
       " 'before',\n",
       " 'point',\n",
       " 'might',\n",
       " 'better',\n",
       " 'using',\n",
       " 'question',\n",
       " 'never',\n",
       " 'things',\n",
       " 'while',\n",
       " 'thanks',\n",
       " 'software',\n",
       " 'david',\n",
       " 'without',\n",
       " 'another',\n",
       " 'number',\n",
       " 'someone',\n",
       " 'access',\n",
       " 'doesn',\n",
       " 'forsale',\n",
       " 'through',\n",
       " 'thing',\n",
       " 'between',\n",
       " 'under',\n",
       " 'drive',\n",
       " 'program',\n",
       " 'available',\n",
       " 'version',\n",
       " 'apple',\n",
       " 'science',\n",
       " 'atheism',\n",
       " 'power',\n",
       " 'anything',\n",
       " 'little',\n",
       " 'columbia',\n",
       " 'around',\n",
       " 'however',\n",
       " 'against',\n",
       " 'again',\n",
       " 'darwin',\n",
       " 'sport',\n",
       " 'every',\n",
       " 'public',\n",
       " 'different',\n",
       " 'seems',\n",
       " 'probably',\n",
       " 'group',\n",
       " 'least',\n",
       " 'research',\n",
       " 'enough',\n",
       " 'actually',\n",
       " 'course',\n",
       " 'support',\n",
       " 'great',\n",
       " '1993apr20',\n",
       " 'washington',\n",
       " 'systems',\n",
       " 'jesus',\n",
       " 'either',\n",
       " 'though',\n",
       " 'nothing',\n",
       " 'called',\n",
       " 'second',\n",
       " 'hockey',\n",
       " 'possible',\n",
       " 'image',\n",
       " 'internet',\n",
       " 'rather',\n",
       " 'wrong',\n",
       " 'stanford',\n",
       " 'turkish',\n",
       " 'reason',\n",
       " 'network',\n",
       " 'athos',\n",
       " 'autos',\n",
       " 'general',\n",
       " 'above',\n",
       " 'others',\n",
       " 'person',\n",
       " 'baseball',\n",
       " 'jewish',\n",
       " 'order',\n",
       " 'based',\n",
       " 'looking',\n",
       " 'problems',\n",
       " 'found',\n",
       " 'agate',\n",
       " 'email',\n",
       " 'maybe',\n",
       " 'technology',\n",
       " 'security',\n",
       " 'human',\n",
       " 'files',\n",
       " 'example',\n",
       " 'having',\n",
       " '1993apr15',\n",
       " 'center',\n",
       " 'place',\n",
       " 'american',\n",
       " '1993apr21',\n",
       " 'three',\n",
       " 'always',\n",
       " 'israel',\n",
       " 'quite',\n",
       " 'purdue',\n",
       " 'following',\n",
       " 'control',\n",
       " 'mideast',\n",
       " 'thought',\n",
       " 'wrote',\n",
       " 'heard',\n",
       " 'doing',\n",
       " 'evidence',\n",
       " 'means',\n",
       " 'michael',\n",
       " 'electronics',\n",
       " 'crypt',\n",
       " 'virginia',\n",
       " 'trying',\n",
       " 'whether',\n",
       " 'phone',\n",
       " 'colorado',\n",
       " 'children',\n",
       " 'opinions',\n",
       " 'haven',\n",
       " 'given',\n",
       " 'start',\n",
       " 'national',\n",
       " 'window',\n",
       " 'today',\n",
       " 'several',\n",
       " 'rights',\n",
       " 'times',\n",
       " 'berkeley',\n",
       " 'geneva',\n",
       " 'getting',\n",
       " 'questions',\n",
       " 'keywords',\n",
       " 'president',\n",
       " 'during',\n",
       " 'remember',\n",
       " 'service',\n",
       " 'games',\n",
       " 'steve',\n",
       " 'change',\n",
       " 'makes',\n",
       " 'standard',\n",
       " 'history',\n",
       " 'followup',\n",
       " 'saying',\n",
       " 'clipper',\n",
       " 'toronto',\n",
       " 'local',\n",
       " 'source',\n",
       " 'wupost',\n",
       " 'wanted',\n",
       " 'price',\n",
       " 'department',\n",
       " 'server',\n",
       " 'perhaps',\n",
       " 'caltech',\n",
       " 'abortion',\n",
       " 'cannot',\n",
       " 'frank',\n",
       " 'already',\n",
       " 'until',\n",
       " 'large',\n",
       " 'bogus',\n",
       " 'institute',\n",
       " 'money',\n",
       " 'stuff',\n",
       " 'small',\n",
       " 'digex',\n",
       " 'motorcycles',\n",
       " '1993apr16',\n",
       " 'answer',\n",
       " 'indiana',\n",
       " 'running',\n",
       " 'address',\n",
       " 'clinton',\n",
       " 'magnus',\n",
       " 'matter',\n",
       " 'speed',\n",
       " 'issue',\n",
       " 'interested',\n",
       " 'bible',\n",
       " 'original',\n",
       " 'agree',\n",
       " 'approved',\n",
       " 'whole',\n",
       " 'works',\n",
       " 'pretty',\n",
       " 'video',\n",
       " '1993apr19',\n",
       " 'legal',\n",
       " 'current',\n",
       " 'states',\n",
       " 'canada',\n",
       " 'claim',\n",
       " 'color',\n",
       " 'machine',\n",
       " 'stratus',\n",
       " 'earth',\n",
       " 'robert',\n",
       " 'armenian',\n",
       " 'everyone',\n",
       " '1993apr22',\n",
       " 'understand',\n",
       " 'everything',\n",
       " 'house',\n",
       " 'often',\n",
       " 'college',\n",
       " 'important',\n",
       " 'simply',\n",
       " 'church',\n",
       " 'programs',\n",
       " 'memory',\n",
       " 'netnews',\n",
       " 'april',\n",
       " 'almost',\n",
       " 'black',\n",
       " 'engineering',\n",
       " 'buffalo',\n",
       " 'truth',\n",
       " 'including',\n",
       " 'include',\n",
       " 'certainly',\n",
       " 'started',\n",
       " 'encryption',\n",
       " 'wouldn',\n",
       " 'white',\n",
       " 'guess',\n",
       " 'cause',\n",
       " 'cornell',\n",
       " 'health',\n",
       " 'making',\n",
       " 'instead',\n",
       " 'soviet',\n",
       " 'value',\n",
       " 'comes',\n",
       " '1993apr23',\n",
       " 'display',\n",
       " 'christians',\n",
       " 'themselves',\n",
       " 'christ',\n",
       " 'later',\n",
       " 'although',\n",
       " 'sandvik',\n",
       " 'working',\n",
       " 'school',\n",
       " 'death',\n",
       " 'newsreader',\n",
       " 'company',\n",
       " 'country',\n",
       " 'anyway',\n",
       " 'private',\n",
       " 'single',\n",
       " 'write',\n",
       " 'unless',\n",
       " 'words',\n",
       " 'consider',\n",
       " 'light',\n",
       " 'within',\n",
       " 'opinion',\n",
       " 'difference',\n",
       " 'society',\n",
       " 'pacific',\n",
       " 'california',\n",
       " 'police',\n",
       " 'armenians',\n",
       " 'faith',\n",
       " 'austin',\n",
       " 'known',\n",
       " 'james',\n",
       " 'tried',\n",
       " 'computers',\n",
       " 'major',\n",
       " 'freenet',\n",
       " 'brian',\n",
       " 'check',\n",
       " 'clear',\n",
       " 'sense',\n",
       " 'anybody',\n",
       " 'bitnet',\n",
       " 'contact',\n",
       " 'political',\n",
       " 'cleveland',\n",
       " 'objective',\n",
       " 'services',\n",
       " 'religious',\n",
       " 'hedrick',\n",
       " 'morality',\n",
       " 'likely',\n",
       " 'aramis',\n",
       " 'iastate',\n",
       " 'talking',\n",
       " 'especially',\n",
       " 'similar',\n",
       " 'radio',\n",
       " 'night',\n",
       " 'argument',\n",
       " 'press',\n",
       " 'package',\n",
       " 'summary',\n",
       " 'koresh',\n",
       " 'correct',\n",
       " 'women',\n",
       " 'couple',\n",
       " 'simple',\n",
       " 'certain',\n",
       " 'happened',\n",
       " 'force',\n",
       " 'sound',\n",
       " 'board',\n",
       " 'peter',\n",
       " 'privacy',\n",
       " 'exactly',\n",
       " 'asked',\n",
       " 'emory',\n",
       " 'third',\n",
       " 'books',\n",
       " 'killed',\n",
       " 'screen',\n",
       " 'israeli',\n",
       " 'driver',\n",
       " 'moral',\n",
       " 'theory',\n",
       " 'provide',\n",
       " 'among',\n",
       " 'sorry',\n",
       " 'situation',\n",
       " 'monitor',\n",
       " 'level',\n",
       " 'common',\n",
       " 'whatever',\n",
       " 'business',\n",
       " 'taken',\n",
       " 'format',\n",
       " 'position',\n",
       " 'myself',\n",
       " 'groups',\n",
       " 'statement',\n",
       " 'reading',\n",
       " 'images',\n",
       " 'become',\n",
       " 'western',\n",
       " 'answers',\n",
       " 'written',\n",
       " 'early',\n",
       " 'motif',\n",
       " 'usually',\n",
       " 'players',\n",
       " 'discussion',\n",
       " 'application',\n",
       " 'peace',\n",
       " 'personal',\n",
       " 'experience',\n",
       " 'scott',\n",
       " 'itself',\n",
       " 'elroy',\n",
       " 'manager',\n",
       " 'interesting',\n",
       " 'except',\n",
       " 'peachnet',\n",
       " 'swrinde',\n",
       " 'division',\n",
       " 'transfer',\n",
       " 'disclaimer',\n",
       " 'period',\n",
       " 'particular',\n",
       " 'microsoft',\n",
       " 'advance',\n",
       " 'arizona',\n",
       " 'users',\n",
       " 'account',\n",
       " 'therefore',\n",
       " 'study',\n",
       " 'according',\n",
       " 'needed',\n",
       " 'posted',\n",
       " 'office',\n",
       " 'astro',\n",
       " 'happen',\n",
       " 'needs',\n",
       " 'short',\n",
       " 'request',\n",
       " 'physics',\n",
       " 'effect',\n",
       " 'special',\n",
       " 'numbers',\n",
       " 'series',\n",
       " 'mouse',\n",
       " 'members',\n",
       " 'corporation',\n",
       " 'front',\n",
       " 'future',\n",
       " 'season',\n",
       " 'texas',\n",
       " 'upenn',\n",
       " 'months',\n",
       " 'ogicse',\n",
       " 'smith',\n",
       " 'exist',\n",
       " 'media',\n",
       " 'output',\n",
       " 'points',\n",
       " 'keith',\n",
       " 'young',\n",
       " 'model',\n",
       " 'greek',\n",
       " 'error',\n",
       " 'thomas',\n",
       " 'drivers',\n",
       " 'medical',\n",
       " 'germany',\n",
       " 'accept',\n",
       " 'expect',\n",
       " 'longer',\n",
       " 'specific',\n",
       " 'considered',\n",
       " 'convex',\n",
       " 'recently',\n",
       " 'communications',\n",
       " 'project',\n",
       " 'return',\n",
       " 'united',\n",
       " 'sources',\n",
       " 'performance',\n",
       " 'coming',\n",
       " 'sometimes',\n",
       " 'taking',\n",
       " 'insurance',\n",
       " 'policy',\n",
       " 'shall',\n",
       " 'worth',\n",
       " 'international',\n",
       " 'process',\n",
       " 'values',\n",
       " 'reference',\n",
       " 'federal',\n",
       " 'offer',\n",
       " 'outside',\n",
       " 'action',\n",
       " 'speak',\n",
       " 'thinking',\n",
       " 'ground',\n",
       " 'built',\n",
       " 'various',\n",
       " 'pittsburgh',\n",
       " 'drives',\n",
       " 'optilink',\n",
       " 'assume',\n",
       " 'military',\n",
       " 'pipex',\n",
       " 'result',\n",
       " 'weapons',\n",
       " 'results',\n",
       " 'chris',\n",
       " 'yourself',\n",
       " 'response',\n",
       " 'quality',\n",
       " 'richard',\n",
       " 'water',\n",
       " 'friend',\n",
       " 'million',\n",
       " 'doubt',\n",
       " 'horus',\n",
       " 'further',\n",
       " 'total',\n",
       " 'environment',\n",
       " 'christianity',\n",
       " 'involved',\n",
       " 'design',\n",
       " 'present',\n",
       " 'build',\n",
       " 'story',\n",
       " 'behind',\n",
       " 'uchicago',\n",
       " 'close',\n",
       " 'strong',\n",
       " 'voice',\n",
       " 'higher',\n",
       " '1993apr5',\n",
       " 'allow',\n",
       " 'includes',\n",
       " 'together',\n",
       " 'explain',\n",
       " 'child',\n",
       " 'computing',\n",
       " '1993apr17',\n",
       " 'league',\n",
       " 'newsserver',\n",
       " 'field',\n",
       " 'necessary',\n",
       " 'cases',\n",
       " 'report',\n",
       " 'along',\n",
       " 'previous',\n",
       " 'uknet',\n",
       " 'george',\n",
       " 'building',\n",
       " 'programmer',\n",
       " 'couldn',\n",
       " 'comments',\n",
       " 'asking',\n",
       " 'looks',\n",
       " 'player',\n",
       " 'leave',\n",
       " 'freedom',\n",
       " 'knowledge',\n",
       " 'related',\n",
       " 'parts',\n",
       " '1993apr6',\n",
       " 'deleted',\n",
       " 'wants',\n",
       " 'issues',\n",
       " 'demon',\n",
       " 'population',\n",
       " 'party',\n",
       " 'armenia',\n",
       " 'athena',\n",
       " 'choice',\n",
       " '1993apr26',\n",
       " 'knows',\n",
       " 'willing',\n",
       " '1993apr14',\n",
       " 'boston',\n",
       " 'crime',\n",
       " 'himself',\n",
       " 'watson',\n",
       " 'technical',\n",
       " 'applications',\n",
       " 'development',\n",
       " 'ideas',\n",
       " 'portal',\n",
       " 'market',\n",
       " 'muslim',\n",
       " 'appreciated',\n",
       " 'decwrl',\n",
       " 'clearly',\n",
       " 'anonymous',\n",
       " 'claims',\n",
       " 'follow',\n",
       " 'modem',\n",
       " 'section',\n",
       " 'mentioned',\n",
       " 'mcgill',\n",
       " 'sounds',\n",
       " 'currently',\n",
       " 'interest',\n",
       " 'complete',\n",
       " 'basis',\n",
       " 'america',\n",
       " 'henry',\n",
       " 'exists',\n",
       " 'nature',\n",
       " 'administration',\n",
       " 'useful',\n",
       " 'takes',\n",
       " 'reasons',\n",
       " 'defense',\n",
       " 'drugs',\n",
       " 'chicago',\n",
       " 'included',\n",
       " 'cover',\n",
       " 'otherwise',\n",
       " 'machines',\n",
       " 'europe',\n",
       " 'completely',\n",
       " 'purpose',\n",
       " 'directory',\n",
       " 'command',\n",
       " 'serious',\n",
       " 'controller',\n",
       " 'existence',\n",
       " 'court',\n",
       " 'scientific',\n",
       " 'average',\n",
       " 'genocide',\n",
       " 'belief',\n",
       " 'living',\n",
       " 'north',\n",
       " 'poster',\n",
       " 'rules',\n",
       " 'gives',\n",
       " 'green',\n",
       " 'cards',\n",
       " 'individual',\n",
       " 'illinois',\n",
       " 'bought',\n",
       " 'father',\n",
       " 'newsgroup',\n",
       " 'family',\n",
       " 'engine',\n",
       " 'created',\n",
       " 'origins',\n",
       " 'below',\n",
       " 'conspiracy',\n",
       " 'mantis',\n",
       " 'required',\n",
       " 'basic',\n",
       " 'serial',\n",
       " 'weeks',\n",
       " 'create',\n",
       " 'community',\n",
       " 'meaning',\n",
       " 'indeed',\n",
       " 'algorithm',\n",
       " 'digital',\n",
       " 'neither',\n",
       " 'chance',\n",
       " 'language',\n",
       " 'inside',\n",
       " 'alaska',\n",
       " 'necessarily',\n",
       " 'brown',\n",
       " 'universe',\n",
       " 'noise',\n",
       " 'manual',\n",
       " 'looked',\n",
       " 'normal',\n",
       " 'gateway',\n",
       " 'appears',\n",
       " 'faster',\n",
       " 'turkey',\n",
       " 'cheap',\n",
       " 'supposed',\n",
       " 'device',\n",
       " 'interface',\n",
       " 'student',\n",
       " 'suggest',\n",
       " 'obviously',\n",
       " 'energy',\n",
       " 'record',\n",
       " 'views',\n",
       " 'thank',\n",
       " 'paper',\n",
       " 'details',\n",
       " 'object',\n",
       " 'class',\n",
       " 'muslims',\n",
       " 'directly',\n",
       " 'finally',\n",
       " 'atheists',\n",
       " 'author',\n",
       " 'mcsun',\n",
       " 'owner',\n",
       " 'shuttle',\n",
       " 'reasonable',\n",
       " 'russian',\n",
       " 'figure',\n",
       " 'commercial',\n",
       " 'learn',\n",
       " 'princeton',\n",
       " 'events',\n",
       " 'final',\n",
       " 'library',\n",
       " 'advice',\n",
       " 'heart',\n",
       " 'civil',\n",
       " 'happy',\n",
       " 'spool',\n",
       " 'mitre',\n",
       " 'hours',\n",
       " 'entire',\n",
       " 'event',\n",
       " 'umich',\n",
       " 'folks',\n",
       " 'joseph',\n",
       " 'amount',\n",
       " 'release',\n",
       " 'products',\n",
       " 'colostate',\n",
       " 'carleton',\n",
       " 'condition',\n",
       " 'secret',\n",
       " 'murdoch',\n",
       " 'terms',\n",
       " 'received',\n",
       " 'function',\n",
       " 'stated',\n",
       " 'oracle',\n",
       " 'processing',\n",
       " 'attack',\n",
       " 'stephen',\n",
       " 'prove',\n",
       " 'entry',\n",
       " 'break',\n",
       " 'product',\n",
       " 'enforcement',\n",
       " 'clock',\n",
       " 'miles',\n",
       " 'matthew',\n",
       " 'actions',\n",
       " 'letter',\n",
       " 'turks',\n",
       " 'adobe',\n",
       " 'illegal',\n",
       " 'msdos',\n",
       " 'responsible',\n",
       " 'wonder',\n",
       " 'definition',\n",
       " 'extra',\n",
       " 'whose',\n",
       " 'cramer',\n",
       " 'easily',\n",
       " 'difficult',\n",
       " 'constitution',\n",
       " 'reality',\n",
       " 'bring',\n",
       " 'station',\n",
       " 'south',\n",
       " 'lives',\n",
       " 'devices',\n",
       " 'conference',\n",
       " 'congress',\n",
       " 'designed',\n",
       " 'printer',\n",
       " 'places',\n",
       " 'tools',\n",
       " 'primate',\n",
       " 'batcomputer',\n",
       " 'limited',\n",
       " 'happens',\n",
       " 'wondering',\n",
       " 'equipment',\n",
       " 'context',\n",
       " 'unfortunately',\n",
       " 'changed',\n",
       " 'alone',\n",
       " 'carry',\n",
       " 'cable',\n",
       " 'reports',\n",
       " 'saimiri',\n",
       " 'citizens',\n",
       " 'allowed',\n",
       " 'americans',\n",
       " 'suppose',\n",
       " 'imagine',\n",
       " 'laboratory',\n",
       " 'mention',\n",
       " 'analysis',\n",
       " 'recent',\n",
       " 'central',\n",
       " 'stand',\n",
       " 'amiga',\n",
       " 'solution',\n",
       " 'method',\n",
       " 'originator',\n",
       " 'physical',\n",
       " 'decided',\n",
       " 'launch',\n",
       " 'companies',\n",
       " 'avoid',\n",
       " 'trouble',\n",
       " 'decision',\n",
       " 'generally',\n",
       " 'facts',\n",
       " '1993apr18',\n",
       " 'studies',\n",
       " 'member',\n",
       " 'attempt',\n",
       " 'street',\n",
       " 'online',\n",
       " 'mnemosyne',\n",
       " 'stupid',\n",
       " 'continue',\n",
       " 'apparently',\n",
       " 'pictures',\n",
       " 'proof',\n",
       " 'compound',\n",
       " 'murder',\n",
       " 'uwaterloo',\n",
       " 'widget',\n",
       " 'psinntp',\n",
       " 'double',\n",
       " 'regarding',\n",
       " 'ctron',\n",
       " 'watch',\n",
       " 'escrow',\n",
       " 'roger',\n",
       " 'chips',\n",
       " 'input',\n",
       " 'define',\n",
       " 'month',\n",
       " 'safety',\n",
       " 'utnut',\n",
       " 'livesey',\n",
       " 'reported',\n",
       " 'archive',\n",
       " 'volume',\n",
       " 'brought',\n",
       " 'intercon',\n",
       " 'forget',\n",
       " 'coverage',\n",
       " 'floppy',\n",
       " 'nobody',\n",
       " 'apollo',\n",
       " 'psuvm',\n",
       " 'switch',\n",
       " 'internal',\n",
       " 'somebody',\n",
       " 'worked',\n",
       " 'official',\n",
       " 'title',\n",
       " 'require',\n",
       " 'middle',\n",
       " 'audio',\n",
       " 'across',\n",
       " 'keyboard',\n",
       " 'installed',\n",
       " 'apply',\n",
       " 'supply',\n",
       " 'serdar',\n",
       " 'disease',\n",
       " 'education',\n",
       " 'mother',\n",
       " 'blood',\n",
       " 'charles',\n",
       " 'atlanta',\n",
       " 'midway',\n",
       " 'homosexuality',\n",
       " 'logic',\n",
       " 'hands',\n",
       " 'range',\n",
       " 'trade',\n",
       " 'obvious',\n",
       " 'argic',\n",
       " 'quote',\n",
       " 'friends',\n",
       " 'worse',\n",
       " 'orbit',\n",
       " 'teams',\n",
       " 'georgia',\n",
       " 'false',\n",
       " 'authority',\n",
       " 'search',\n",
       " 'protect',\n",
       " 'suspect',\n",
       " 'mission',\n",
       " 'names',\n",
       " 'killing',\n",
       " 'excellent',\n",
       " 'giving',\n",
       " 'starting',\n",
       " 'natural',\n",
       " 'music',\n",
       " 'larry',\n",
       " 'amendment',\n",
       " 'shipping',\n",
       " 'medicine',\n",
       " 'linac',\n",
       " 'areas',\n",
       " 'contains',\n",
       " 'choose',\n",
       " 'boulder',\n",
       " 'appropriate',\n",
       " 'effective',\n",
       " 'islam',\n",
       " 'shows',\n",
       " 'resources',\n",
       " 'limbaugh',\n",
       " 'writing',\n",
       " 'appear',\n",
       " 'material',\n",
       " 'disks',\n",
       " 'addition',\n",
       " 'approach',\n",
       " 'saturn',\n",
       " 'cambridge',\n",
       " 'requires',\n",
       " 'driving',\n",
       " 'lower',\n",
       " 'respect',\n",
       " 'fonts',\n",
       " 'modern',\n",
       " 'social',\n",
       " 'destroyer',\n",
       " 'ability',\n",
       " 'published',\n",
       " 'homosexual',\n",
       " 'caused',\n",
       " 'former',\n",
       " 'beyond',\n",
       " 'suggestions',\n",
       " 'uoknor',\n",
       " 'protection',\n",
       " 'costs',\n",
       " '_____',\n",
       " 'd012s658',\n",
       " 'intel',\n",
       " 'picture',\n",
       " 'mormons',\n",
       " 'provided',\n",
       " 'trust',\n",
       " 'secure',\n",
       " 'kevin',\n",
       " 'added',\n",
       " 'electronic',\n",
       " 'posts',\n",
       " 'heaven',\n",
       " '1993apr27',\n",
       " 'earlier',\n",
       " 'basically',\n",
       " 'somewhere',\n",
       " 'calls',\n",
       " 'understanding',\n",
       " 'practice',\n",
       " 'treatment',\n",
       " 'independent',\n",
       " 'possibly',\n",
       " 'administrator',\n",
       " 'stephanopoulos',\n",
       " 'countries',\n",
       " 'prevent',\n",
       " 'comment',\n",
       " 'majority',\n",
       " 'turned',\n",
       " 'expressed',\n",
       " 'mailing',\n",
       " 'firearms',\n",
       " 'british',\n",
       " 'gordon',\n",
       " 'regular',\n",
       " 'perfect',\n",
       " 'justice',\n",
       " 'master',\n",
       " 'lehigh',\n",
       " 'beliefs',\n",
       " 'leland',\n",
       " 'played',\n",
       " 'print',\n",
       " 'berlin',\n",
       " 'seriously',\n",
       " 'programming',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-processing the data\n",
    "def clean(s): # cleans the string by removing punctuations\n",
    "        translator=str.maketrans(\"\",\"\",string.punctuation)\n",
    "        return s.translate(translator)\n",
    "    \n",
    "def tokenize(text): # tokenizes our string into words\n",
    "    text=text.lower()\n",
    "    return re.split(\"\\W+\",text)\n",
    "\n",
    "def stop_word_remover(s):\n",
    "    relevant=[]\n",
    "    stop_words=['a','for','are','when','were','then','them','some','also','just','1993','as','on','if','will','here','there','their','with','will','all','what','at','my','who','but','so','or','would','can','be','i','you','by','your','we','was','an','that','they','which','the','in','are,''that','he','she','should','you','yours','it','has','have','is','this','had','could','from','to','of','and','an']\n",
    "    new=tokenize(s)\n",
    "    for word in new:\n",
    "         if word not in stop_words and len(word)>=5:\n",
    "                relevant.append(word)\n",
    "    return relevant \n",
    "\n",
    "vocabulary=[] \n",
    "data=[]\n",
    "for m in range(0,20): \n",
    "    data= data+ get_data(DATA_DIRECTORY)[subfolders[m]]\n",
    "len(data) # consists of all strings of each document from 0 to 20\n",
    "\n",
    "final=[]\n",
    "for i in range(len(data)):\n",
    "    temp=stop_word_remover(data[i])\n",
    "    for j in range(len(temp)):\n",
    "        final.append(temp[j])\n",
    "\n",
    "\n",
    "def get_word_counts(words):\n",
    "    # how many times each word appears in a list of words\n",
    "    word_counts={}\n",
    "    vocab=[]\n",
    "    for word in words:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "            word_counts[word]=1\n",
    "        else:\n",
    "            word_counts[word]=word_counts[word] +1\n",
    "    return word_counts\n",
    "\n",
    "word_counts=get_word_counts(final)\n",
    "\n",
    "s = [k for k in sorted(word_counts, key=word_counts.get, reverse=True)]\n",
    "\n",
    "for i in range(0,5000): # here we are selecting top 5000 words\n",
    "    vocabulary.append(s[i])\n",
    "    \n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=[] # gives the class of each folder\n",
    "docs=[] # contains list of words in each document docs[i]-> list of words in document i.\n",
    "\n",
    "for m in range(0,20): \n",
    "    data= get_data(DATA_DIRECTORY)[subfolders[m]] \n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data[i]= tokenize(data[i])\n",
    "        docs.append(data[i])\n",
    "        Y.append(m)\n",
    "        \n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [2., 1., 1., ..., 0., 0., 0.],\n",
       "       [2., 1., 1., ..., 0., 0., 0.],\n",
       "       [2., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialising X as an array containing zeros and having desired dimensions\n",
    "import numpy as np\n",
    "X= np.zeros((len(docs),len(vocabulary)))\n",
    "\n",
    "\n",
    "for row in range(len(docs)):\n",
    "    for word in range(len(docs[row])):\n",
    "        for column in range(len(vocabulary)):\n",
    "            if(docs[row][word]==vocabulary[column]):\n",
    "                X[row][column]+=1 \n",
    "            \n",
    "\n",
    "print(len(X)) \n",
    "# X=the required np array with top vocabulary words as features and each row as a document giving frequency of each vocabulary word that occurs in the document\n",
    "# Y gives the index no. of subfolder to which the document belongs\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "x_train,x_test,y_train,y_test= train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       272\n",
      "           1       0.85      0.80      0.82       235\n",
      "           2       0.74      0.88      0.80       249\n",
      "           3       0.73      0.76      0.75       276\n",
      "           4       0.71      0.77      0.74       232\n",
      "           5       0.93      0.75      0.83       264\n",
      "           6       0.83      0.93      0.87       255\n",
      "           7       0.87      0.93      0.89       229\n",
      "           8       0.92      0.93      0.93       248\n",
      "           9       0.96      0.94      0.95       240\n",
      "          10       0.95      0.98      0.97       245\n",
      "          11       0.98      0.95      0.96       228\n",
      "          12       0.87      0.82      0.84       239\n",
      "          13       0.97      0.82      0.89       254\n",
      "          14       0.95      0.95      0.95       275\n",
      "          15       0.97      1.00      0.98       244\n",
      "          16       0.80      0.93      0.86       246\n",
      "          17       0.94      0.91      0.93       268\n",
      "          18       0.81      0.70      0.75       248\n",
      "          19       0.68      0.57      0.62       253\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred=clf.predict(x_test)\n",
    "confusion_matrix(y_test,y_test_pred)\n",
    "print(classification_report(y_test,y_test_pred))\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X,y,alpha = 1.0):\n",
    "    count = X.shape[0]\n",
    "    separate = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
    "    log_prior = [np.log(len(i) / count) for i in separate]\n",
    "    count_1 = np.array([np.array(i).sum(axis=0) for i in separate]) + alpha\n",
    "    feature_prob = np.log(count_1 / count_1.sum(axis=1)[np.newaxis].T)\n",
    "    return feature_prob,log_prior\n",
    "\n",
    "def predict_log_prob(feature_prob,log_prior,X):\n",
    "    return [(feature_prob * x).sum(axis=1) + log_prior\n",
    "                for x in X]\n",
    "\n",
    "def predict(feature_prob,log_prior, X):\n",
    "    return np.argmax(predict_log_prob(feature_prob,log_prior,X), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       272\n",
      "           1       0.85      0.80      0.82       235\n",
      "           2       0.74      0.88      0.80       249\n",
      "           3       0.73      0.76      0.75       276\n",
      "           4       0.71      0.77      0.74       232\n",
      "           5       0.93      0.75      0.83       264\n",
      "           6       0.83      0.93      0.87       255\n",
      "           7       0.87      0.93      0.89       229\n",
      "           8       0.92      0.93      0.93       248\n",
      "           9       0.96      0.94      0.95       240\n",
      "          10       0.95      0.98      0.97       245\n",
      "          11       0.98      0.95      0.96       228\n",
      "          12       0.87      0.82      0.84       239\n",
      "          13       0.97      0.82      0.89       254\n",
      "          14       0.95      0.95      0.95       275\n",
      "          15       0.97      1.00      0.98       244\n",
      "          16       0.80      0.93      0.86       246\n",
      "          17       0.94      0.91      0.93       268\n",
      "          18       0.81      0.70      0.75       248\n",
      "          19       0.68      0.57      0.62       253\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_prob,log_prior = fit(x_train,y_train)\n",
    "y_test_pred1 = predict(feature_prob,log_prior,x_test)\n",
    "confusion_matrix(y_test,y_test_pred1)\n",
    "print(classification_report(y_test,y_test_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82785415, 0.82363527, 0.82590361])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation scores\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can observe that the results obtained by the in-built Naive Bayes and or own implementation are the same. \n",
    "# We can thus conclude that we have correctly compiled our own version of Naive Bayes. This can further be optimised by including all the functions that we buit within a class and then creating an object of that class.\n",
    "#The code for doing the same is as follows :\n",
    "class MyMultinomialNB(object):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        count_sample = X.shape[0]\n",
    "        separated = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
    "        self.class_log_prior_ = [np.log(len(i) / count_sample) for i in separated]\n",
    "        count = np.array([np.array(i).sum(axis=0) for i in separated]) + self.alpha\n",
    "        self.feature_log_prob_ = np.log(count / count.sum(axis=1)[np.newaxis].T)\n",
    "        return self\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        return [(self.feature_log_prob_ * x).sum(axis=1) + self.class_log_prior_\n",
    "                for x in X]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_log_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyMultinomialNB at 0x1a9ef32860>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = MyMultinomialNB()\n",
    "clf1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       272\n",
      "           1       0.85      0.80      0.82       235\n",
      "           2       0.74      0.88      0.80       249\n",
      "           3       0.73      0.76      0.75       276\n",
      "           4       0.71      0.77      0.74       232\n",
      "           5       0.93      0.75      0.83       264\n",
      "           6       0.83      0.93      0.87       255\n",
      "           7       0.87      0.93      0.89       229\n",
      "           8       0.92      0.93      0.93       248\n",
      "           9       0.96      0.94      0.95       240\n",
      "          10       0.95      0.98      0.97       245\n",
      "          11       0.98      0.95      0.96       228\n",
      "          12       0.87      0.82      0.84       239\n",
      "          13       0.97      0.82      0.89       254\n",
      "          14       0.95      0.95      0.95       275\n",
      "          15       0.97      1.00      0.98       244\n",
      "          16       0.80      0.93      0.86       246\n",
      "          17       0.94      0.91      0.93       268\n",
      "          18       0.81      0.70      0.75       248\n",
      "          19       0.68      0.57      0.62       253\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      5000\n",
      "   macro avg       0.86      0.86      0.86      5000\n",
      "weighted avg       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred1=clf1.predict(x_test)\n",
    "confusion_matrix(y_test,y_test_pred1)\n",
    "print(classification_report(y_test,y_test_pred1))\n",
    "#clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us the same result in a more optimised way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
